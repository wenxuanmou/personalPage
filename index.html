<!DOCTYPE html>

<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml" lang="en"><head>
  <title>Wenxuan Mou</title>

  
  
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  
  <meta name="generator" content="Bluefish 2.2.3">

<!-- Internet Explorer fix, forces IE8 into newest possible rendering

         engine even if it's on an intranet. This has to be defined before any

         script/style tags. -->
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!--[if lt IE 7]></base><![endif]--><!-- IE6 workaround CSS/JS  --><!--[if lte IE 7]>

        <style type="text/css" media="all">@import url(http://liris.cnrs.fr/IEFixes.css);

.style1 {

  font-size: xx-small;

}

</style>

<script type="text/javascript"

src="http://liris.cnrs.fr/iefixes.js">

</script>



    <![endif]-->
  
  <link rel="shortcut icon" href="images/fav.ico">

</head><body>
<br>

<table align="center" width="800">

</table>

<table align="center" border="0" width="650">

  <tbody>
    <tr align="center">
      <td align="center" valign="top" width="100"> <img src="IMG_8796.JPG" width="319px" height="270px"><br>
      </td>
      <td align="center" valign="top" width="10"><br>
      </td>
      <td align="left" width="540">
      <p class="titre"> </p>
      <h3 class="titre">Dr Wenxuan Mou (牟雯萱) </h3>
        <h4>  Postdoctoral Researcher</h4>
<a href="https://corolab.github.io" target="_blank">COGNITIVE ROBOTICS LAB (COROLAB)</a>  <br>
Department of Computer Science <br>
<a href="https://www.manchester.ac.uk" target="_blank"> University of Manchester</a> <br>
Oxford Road, Manchester UK <br>
      <p class="texte"> </p>
      
      </td>
    </tr>
    <tr>
    </tr>
  </tbody>
</table>
<html>
<body>

<table align="center" border="0" cellpadding="0" cellspacing="0" width="650">

  <tbody>
    <tr>
      <td colspan="3" class="titre" height="34">
      <h3 class="titre">Welcome</h3>
      </td>
    </tr>
    <tr>
      <td align="justify" width="650">
      I am currently a postdoctoral researcher working on the <a href="https://thrivemanchesteruniversity.wordpress.com" target="_blank"> THRIVE++</a> project that is funded by the Air Force Office of Scientific Research (AFOSR-EOARD) with the aim 
      of investigating the embodiment and socio-cognitive mechanisms in the development of trust between humans and robots involved in interactions and joint tasks. 
      
      I am also working on the <a href="https://trust.tas.ac.uk" target="_blank"> UKRI Trustworthy Autonomous Systems project node on Trust</a> that aims at Investigating how to build, maintain and manage trust in 
      robotic and autonomous systems. Prior to that, my research was under the scope of the H2020 EU project <a href="http://www.movecare-project.eu" target="_blank"> MoveCare</a> focusing on designing machine learning methods for HRI and elderly care.
    
    </tr>
    
    
  </tbody>
</table>
  
  
<table align="center" border="0" cellpadding="0" cellspacing="0" width="650">

  <tbody>
    <tr>
      <td colspan="3" class="titre" height="34">
      <h3 class="titre">Research Interests</h3>
      </td>
    </tr>
    <tr>
      <td align="justify" width="650">
      <li>Affective Computing<br>
      </li>
      <li>Human-Robot Interaction</li>
      </li>
      <li>Computer Vision<br>
      </li>
      <li>Machine Learning<br>
      </li>
    </tr>
  </tbody>
</table>
<table align="center" border="0" cellpadding="0" cellspacing="0" width="650">

  <tbody>
    <tr>
      <td colspan="2" class="titre" height="30">
      <h3 class="titre">Education</h3>
      </td>
    </tr>
    <tr>
      <td align="justify" width="650">
      </li>
      <li>2018.08 - 2019.03, Research Assistant, Department of Computer Science and Technology, University of Cambridge, UK <br>
      <li>2014.11 - 2019.04, PhD, School of Electronic Engineering and Computer Science (EECS),
Queen Mary University of London, UK <br>
      <li>2013 - 2014, MSc,  School of Electronic Engineering and Computer Science (EECS),
Queen Mary University of London, UK <br>
      
      </li>
    </tr>
  </tbody>
</table>
<table align="center" border="0" cellpadding="0" cellspacing="0" width="650">


<tbody>
    <tr>
      <td colspan="2" class="titre" height="30">
      <h3 class="titre">Industrial experience</h3>
      </td>
    </tr>
    <tr>
      <td align="justify" width="650">
      </li>
      <li>2017.10 - 2018.04, Internship, at Mitsubishi Electric Research Laboratories <a href="http://www.merl.com/" target="_blank">(MERL)</a>, Cambridge, USA <br>
      </li>
    </tr>
  </tbody>
</table>
<table align="center" border="0" cellpadding="0" cellspacing="0" width="650">


<tbody>
    <tr>
      <td colspan="2" class="titre" height="30">
      <h3 class="titre">Media coverage</h3>
      </td>
    </tr>
    <tr>
      <td align="justify" width="650">
      </li>
      <li> Robots for Resilient Infrastructure Challenge 2017<a href="https://www.youtube.com/watch?v=fSWmPx4rN0E&list=PLHQwOg6p45EbR70DVkGD6O9_r5V0FuVLs" target="_blank">(Youtube)</a> <br>
      </li>
    </tr>
  </tbody>
</table>
<table align="center" border="0" cellpadding="0" cellspacing="0" width="650">


  <tbody>
    <tr>
      <td colspan="2" class="titre" height="30">
      <h3 class="titre">Publications[<a href="http://scholar.google.co.uk/citations?hl=en&user=qWSFJqcAAAAJ&amp;hl=en" target="_blank">Google Scholar Profile</a>] </h3>
      </td>
    </tr>
    <tr>
      <td align="justify" width="650">
    </tr>







<tr>
      <td class="titre" height="34">
      <h4 class="titre">Journal Papers: </h4>

<li>
<p align="justify"> 
<strong>Wenxuan Mou</strong>, Hatice Gunes and Ioannis Patras, <a href="https://dl.acm.org/doi/10.1145/3321509" target="_blank">“Alone vs in-a-group: A Multi-modal Framework for Automatic Affect Recognition”</a>, <em>ACM Transactions on Multimedia Computing Communicationsand Applications, 2019.</em> 
</a></li>
<li>
<p align="justify"> 
<strong>Wenxuan Mou</strong>, Christos  Tzelepis,  Hatice Gunes, Vasileios  Mezaris and Ioannis Patras, <a href="https://www.sciencedirect.com/science/article/pii/S0262885618301501" target="_blank">“Deep Generic to Specific Recognition Model for Group Membership Analysis using Non-verbal Cues”</a>, <em>Image and Vision Computing, 2018.</em> 
</a></li>
<li>
<p align="justify"> 
Shan Luo, <strong>Wenxuan Mou</strong>, Kaspar Althoefer and Hongbin Liu, <a href="https://www.springerprofessional.de/en/iclap-shape-recognition-by-combining-proprioception-and-touch-se/15876352" target="_blank">“iCLAP: Object Recognition by combining
proprioception and tactile sensing”, </a><em>Autonomous Robots, 2018.</em> 
</a></li>
<li>
<p align="justify"> 
Shan Luo, <strong>Wenxuan Mou</strong>, Kaspar Althoefer and Hongbin Liu, <a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7109817" target="_blank">“Novel Tactile-SIFT Descriptor for Object Shape Recognition”, </a><em>IEEE Sensors Journal, 2015.</em> 
</a></li>

      </td>
    </tr>


    <tr>
      <td align="justify" width="650">
<p><span class="titre">
        <h4 class="titre">International Conference &amp; Workshop
Proceedings: </h4>
        </span></p>
<li>
<p align="justify"> 
<strong>Wenxuan Mou</strong>, Martina Ruocco,  Debora Zanatto and Angelo Cangelosi, <a href="http://ro-man2020.unina.it/program.php" target="_blank"> “When Would You Trust a Robot? A Study on Trust and Theory of Mind in Human-Robot Interaction”</a>, <em>IEEE International Conference on Robot and Human Interactive Communication (RO-MAN), 2020.</em>
</a></li>
<li>
<p align="justify"> 
<strong>Wenxuan Mou*</strong>, Abhinav Kumar*, Tim Marks*, Ye Wang, Michael Jones,  Anoop Cherian, Toshiaki Koike-Akino, Xiaoming Liu, Chen Feng, <a href="http://cvlab.cse.msu.edu/pdfs/kumar_marks_mou_wang_jones_cherian_akino_liu_feng_cvpr2020.pdf" target="_blank"> “LUVLi Face Alignment: Estimating Landmarks’ Location, Uncertainty, and Visibility Likelihood”</a>, <em> International Conference on Computer Vision and Pattern Recognition (CVPR), 2020.</em> [* equal first authors]
</a></li>
<li>
<p align="justify"> 
<strong>Wenxuan Mou*</strong>, Abhinav Kumar*, Tim Marks*, Chen Feng, Xiaoming Liu, <a href="https://www.merl.com/publications/docs/TR2019-117.pdf" target="_blank"> “UGLLI Face Alignment: Estimating Uncertainty with Gaussian Log-Likelihood Loss”</a>, <em> International Conference on Computer Vision Workshops (ICCVW), 2019.</em> [Best Oral Paper Award, * equal first authors]
</a></li>
<li>
<p align="justify"> 
<strong>Wenxuan Mou</strong>, Hatice Gunes and Ioannis Patras, <a href="https://www.repository.cam.ac.uk/handle/1810/290131" target="_blank"> “Your Fellows Matter: Affect Analysis across Subjects in Group Videos”</a>, <em> IEEE International Conference
on Automatic Face and Gesture Recognition (FG), 2019.</em> 
</a></li>
<li>
<p align="justify"> 
<strong>Wenxuan Mou</strong>, Christos  Tzelepis,  Hatice Gunes, Vasileios  Mezaris and Ioannis Patras, <a href="http://ieeexplore.ieee.org/abstract/document/7961784/" target="_blank"> “Generic to Specific Recognition Models for Membership Analysis in Group Videos”</a>, <em> IEEE International Conference
on Automatic Face and Gesture Recognition (FG), 2017.</em> [Oral]
</a></li>
<li>
<p align="justify"> 
<strong>Wenxuan Mou</strong>, Hatice Gunes and Ioannis Patras, <a href="https://www.researchgate.net/publication/310819974_Alone_versus_In-a-group_A_Comparative_Analysis_of_Facial_Affect_Recognition" target="_blank">“Alone versus In-a-group: A Comparative Analysis of Facial Affect Recognition”</a>, <em>ACM Multimedia Conference. Amsterdam, 2016.
</a></li>
<li>
<p align="justify"> 
Shan Luo <strong>Wenxuan Mou</strong>, Kaspar Althoefer and Hongbin Liu, <a href="https://www.researchgate.net/profile/Shan_Luo/publication/308938416_Iterative_Closest_Labeled_Point_for_Tactile_Object_Shape_Recognition/links/57f8eed008ae91deaa6144af.pdf" target="_blank">“Iterative Closest Labeled Point for Tactile Object Shape Recognition”</a>, <em>IEEE/RSJ International Conference on Intelligent Robots and Systems(IROS), 2016.
</a></li>
<li>
<p align="justify"> 
<strong>Wenxuan Mou</strong>, Hatice Gunes and Ioannis Patras, <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016_workshops/w28/papers/Mou_Automatic_Recognition_of_CVPR_2016_paper.pdf" target="_blank">“Automatic Recognition of Emotions and Membership in Group Videos”</a>, <em>International Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, Context-Based Affect Recognition, 2016.
</a></li>

<li>
<p align="justify"> 
Heng Yang, <strong>Wenxuan Mou</strong>, Yichi Zhang, Ioannis Patras, Hatice Gunes and Peter Robinson, <a href="http://arxiv.org/pdf/1507.03148v2.pdf" target="_blank">“Face Alignment Assisted by Head Pose Estimation”</a>, <em> British Machine Vision Conference (BMVC), 2015.</em>
</a>
</li>
<li>
<p align="justify"> 
<strong>Wenxuan Mou</strong>, Oya Celiktutan and Hatice
Gunes, <a href="http://ieeexplore.ieee.org/abstract/document/7284862/" target="_blank">“Group-level Arousal and Valence Recognition in Static Images:
Face, Body and Context”</a>, <em>International Workshop on Emotion
Representation, Analysis and Synthesis, IEEE International Conference
on Automatic Face and Gesture Recognition (FG), 2015</em>
</li>

<li>
<p align="justify"> 
Shan Luo, <strong>Wenxuan Mou</strong>, Kaspar Althoefer and Hongbin Liu, <a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7139743" target="_blank">“Localizing the object contact through matching tactile features with visual map”, </a><em>IEEE International Conference
on Robotics and Automation (ICRA), 2015.</em> 
</a></li>

<li>
<p align="justify"> 
Shan Luo, <strong>Wenxuan Mou</strong>, Min Li, Kaspar Althoefer and Hongbin Liu, <a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6985179" target="_blank">“Rotation and translation invariant object recognition with a tactile sensor”, </a><em>IEEE Sensors Conference, 2015.</em> 
</a></li>
  </tbody>
</table>
</body>
</html>
